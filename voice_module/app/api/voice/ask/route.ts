import { NextRequest, NextResponse } from "next/server";
import { readFile, writeFile } from "fs/promises";
import path from "path";
import { askEcho } from "../../../../lib/echo";
import { ElevenLabsError, textToSpeech } from "../../../../lib/elevenlabs";

export const runtime = "nodejs";

// Allow longer response time — AI + TTS can take a while
export const maxDuration = 60;

async function getVoiceId(): Promise<string | null> {
  try {
    const idPath = path.join(process.cwd(), "voice_profiles", "active_voice_id.txt");
    return (await readFile(idPath, "utf8")).trim() || null;
  } catch {
    return null;
  }
}

async function updateActiveTxt(settings: {
  stability?: number;
  similarity_boost?: number;
  style?: number;
  speaker_boost?: boolean;
}): Promise<void> {
  const lines = [
    "# Echo tone profile (auto-updated per question)",
    `stability: ${settings.stability ?? 0.45}`,
    `similarity_boost: ${settings.similarity_boost ?? 0.85}`,
    `style: ${settings.style ?? 0.35}`,
    `speaker_boost: ${settings.speaker_boost ?? true}`,
    "",
    "---",
    "Auto-generated by /api/voice/ask based on emotional tone analysis.",
  ];
  const fullPath = path.join(process.cwd(), "voice_profiles", "active.txt");
  await writeFile(fullPath, lines.join("\n"), "utf8");
}

export async function POST(req: NextRequest) {
  try {
    const body = (await req.json()) as { question?: string };
    const question = body.question?.trim();

    if (!question) {
      return NextResponse.json({ error: "Missing question" }, { status: 400 });
    }

    const voiceId = await getVoiceId();
    if (!voiceId) {
      return NextResponse.json(
        { error: "No voice cloned yet. Record a voice sample first." },
        { status: 400 }
      );
    }

    // Step 1: Get AI-generated answer + dynamic voice settings
    const { answer, voiceSettings, tone } = await askEcho(question);

    // Step 2: Update active.txt with the dynamic settings
    await updateActiveTxt(voiceSettings);

    // Step 3: Clean text for TTS (strip emojis — they cause choppy audio)
    const cleanText = answer.replace(/[\u{1F300}-\u{1FAFF}\u{2600}-\u{27BF}\u{FE00}-\u{FE0F}\u{200D}]/gu, "").replace(/\s{2,}/g, " ").trim();

    // Step 4: Generate speech with the dynamic settings
    const { audio } = await textToSpeech({
      voice_id: voiceId,
      text: cleanText,
      voice_settings: voiceSettings,
    });

    // Return both text answer and audio as base64
    const audioBase64 = Buffer.from(audio).toString("base64");

    return NextResponse.json({
      answer,
      audio: audioBase64,
      tone,
      voiceSettings,
    });
  } catch (err) {
    if (err instanceof ElevenLabsError) {
      return NextResponse.json(
        { error: `ElevenLabs: ${err.message}` },
        { status: err.status || 502 }
      );
    }

    const message = err instanceof Error ? err.message : "Unexpected error";
    console.error("ask endpoint error:", err);
    return NextResponse.json({ error: message }, { status: 500 });
  }
}
